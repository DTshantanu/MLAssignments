{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthcm</th>\n",
       "      <th>SepalWidthcm</th>\n",
       "      <th>PetalLengthcm</th>\n",
       "      <th>PetalWidthcm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthcm  SepalWidthcm  PetalLengthcm  PetalWidthcm         Species\n",
       "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
       "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
       "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
       "148            6.2           3.4            5.4           2.3  Iris-virginica\n",
       "149            5.9           3.0            5.1           1.8  Iris-virginica"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iris.csv',names=['SepalLengthcm','SepalWidthcm','PetalLengthcm','PetalWidthcm','Species'])\n",
    "\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sepal length and sepal width of setosa and versicolor for our binary calssification problem\n",
    "X = df.iloc[:, 0:4].values\n",
    "\n",
    "y = df.iloc[:, 4].values\n",
    "# set output lable value to 1 if it is setosa and 0 if versicolor.\n",
    "y = np.where(y == 'Iris-setosa', 1, 0)\n",
    "#print(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features standerdization\n",
    "X_std = np.copy(X)\n",
    "\n",
    "X_std[:,0] = (X_std[:,0] - X_std[:,0].mean()) / X_std[:,0].std()\n",
    "X_std[:,1] = (X_std[:,1] - X_std[:,1].mean()) / X_std[:,1].std()\n",
    "X_std[:,2] = (X_std[:,2] - X_std[:,2].mean()) / X_std[:,2].std()\n",
    "X_std[:,3] = (X_std[:,3] - X_std[:,3].mean()) / X_std[:,3].std()\n",
    "#print(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Logistic Regression hypothesis or sigmoid function\n",
    "def sigmoid(value):\n",
    "    return 1.0 / ( 1.0 + np.exp(-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Logistic Regression Cost Function\n",
    "def RSS(X, y, betas):\n",
    "    j=0\n",
    "    predicted_value=betas[0] + np.dot(X_std[:,0], betas[1]) + np.dot(X_std[:,1], betas[2]) + np.dot(X_std[:,2], betas[3]) + np.dot(X_std[:,3], betas[4])\n",
    "    #y = y[i]\n",
    "    hx=sigmoid(predicted_value)\n",
    "    # compute cost for given theta parameters\n",
    "    j = -y.dot(np.log(hx)) - ((1 - y).dot(np.log(1-hx)))\n",
    "    #rss = rss + ((-actual_value*np.log(pred_value)) - ((1-actual_value)*np.log(1-pred_value))) \n",
    "    return (j/X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_value_for_ithRow(X,i,betas):\n",
    "    return (1/(1.0 + np.exp(-(betas[0] + np.dot(X_std[:,0], betas[1]) + np.dot(X_std[:,1], betas[2]) + np.dot(X_std[:,2], betas[3]) + np.dot(X_std[:,3], betas[4])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentAlgorithm(x, y, learning_rate):\n",
    "    \n",
    "    print (\"Training Linear Regression Model using Gradient Descent\")\n",
    "    \n",
    "    maximum_iterations = 5000\n",
    "    converge_status = False\n",
    "    \n",
    "    # num_rows stores the number of datapoints in the current dataset provided for training.\n",
    "    num_rows = x[0].shape[0]\n",
    "\n",
    "    # Initial Value of parameters ((beta_0, beta_1) - for our simple linear regression case)\n",
    "    betas = [0,0,0,0,0]\n",
    "\n",
    "    # Initial Error or RSS(beta_0,beta_1) based on the initial parameter values\n",
    "    error = RSS(x, y, betas)\n",
    "    print('Initial Value of RSS (Cost Function)=', error);\n",
    "    \n",
    "    # Iterate Loop\n",
    "    num_iter = 0\n",
    "    while not converge_status:\n",
    "        # for each training sample, compute the gradient (d/d_beta j(beta))\n",
    "        gradient_0 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i]) for i in range(num_rows)]) \n",
    "        gradient_1 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[0][i] for i in range(num_rows)])\n",
    "        gradient_2 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[1][i] for i in range(num_rows)])\n",
    "        gradient_3 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[2][i] for i in range(num_rows)])\n",
    "        gradient_4 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[3][i] for i in range(num_rows)])\n",
    "        \n",
    "        # Computation of new parameters according to the current gradient.\n",
    "        temp0 = betas[0] - learning_rate * gradient_0\n",
    "        temp1 = betas[1] - learning_rate * gradient_1\n",
    "        temp2 = betas[2] - learning_rate * gradient_2\n",
    "        temp3 = betas[3] - learning_rate * gradient_3\n",
    "        temp4 = betas[4] - learning_rate * gradient_4\n",
    "        \n",
    "    \n",
    "        # Simultaneous Update of Parameters Beta_0 and Beta_1.\n",
    "        betas[0] = temp0\n",
    "        betas[1] = temp1\n",
    "        betas[2] = temp2\n",
    "        betas[3] = temp3\n",
    "        betas[4] = temp4\n",
    "               \n",
    "        current_error = RSS(x, y, betas)\n",
    "        \n",
    "        if num_iter % 250 == 0:\n",
    "            print ('Iteration',num_iter+1,'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', current_error)\n",
    "            \n",
    "        error = current_error   # update error \n",
    "        num_iter = num_iter + 1  # update iter\n",
    "    \n",
    "        if num_iter == maximum_iterations:\n",
    "            print (\"Training Interrupted as Maximum number of iterations were crossed.\\n\\n\")\n",
    "            converge_status = True\n",
    "\n",
    "    return (betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression Model using Gradient Descent\n",
      "('Initial Value of RSS (Cost Function)=', 0.6931471805599453)\n",
      "('Iteration', 1, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471806016118)\n",
      "('Iteration', 251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471910182788)\n",
      "('Iteration', 501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472014349463)\n",
      "('Iteration', 751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472118516151)\n",
      "('Iteration', 1001, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.693147222268284)\n",
      "('Iteration', 1251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472326849532)\n",
      "('Iteration', 1501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472431016239)\n",
      "('Iteration', 1751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472535182949)\n",
      "('Iteration', 2001, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472639349662)\n",
      "('Iteration', 2251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472743516381)\n",
      "('Iteration', 2501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472847683114)\n",
      "('Iteration', 2751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.693147295184985)\n",
      "('Iteration', 3001, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931473056016589)\n",
      "('Iteration', 3251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931473160183337)\n",
      "('Iteration', 3501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931473264350095)\n",
      "('Iteration', 3751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931473368516854)\n",
      "('Iteration', 4001, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.693147347268362)\n",
      "('Iteration', 4251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931473576850393)\n",
      "('Iteration', 4501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931473681017178)\n",
      "('Iteration', 4751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931473785183964)\n",
      "Training Interrupted as Maximum number of iterations were crossed.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# m = Number of training examples\n",
    "# n = number of features\n",
    "3#, n = X.shape\n",
    "\n",
    "# initialize theta(weights) parameters to zeros\n",
    "#theta = np.zeros(1+n)\n",
    "#print(theta)\n",
    "\n",
    "# set learning rate to 0.01 and number of iterations to 500\n",
    "#alpha = 0.01\n",
    "#num_iter = 5000\n",
    "\n",
    "coefficients = gradientDescentAlgorithm(X_std,y,0.0000000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression Model using Gradient Descent\n",
      "('Initial Value of RSS (Cost Function)=', 0.6931471805599453)\n",
      "('Iteration', 1, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471805682785)\n",
      "('Iteration', 251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471826516122)\n",
      "('Iteration', 501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471847349451)\n",
      "('Iteration', 751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471868182787)\n",
      "('Iteration', 1001, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471889016123)\n",
      "('Iteration', 1251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471909849454)\n",
      "('Iteration', 1501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471930682792)\n",
      "('Iteration', 1751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471951516129)\n",
      "('Iteration', 2001, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471972349459)\n",
      "('Iteration', 2251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931471993182797)\n",
      "('Iteration', 2501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472014016136)\n",
      "('Iteration', 2751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472034849467)\n",
      "('Iteration', 3001, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472055682806)\n",
      "('Iteration', 3251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472076516144)\n",
      "('Iteration', 3501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472097349478)\n",
      "('Iteration', 3751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472118182818)\n",
      "('Iteration', 4001, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472139016155)\n",
      "('Iteration', 4251, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.693147215984949)\n",
      "('Iteration', 4501, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472180682828)\n",
      "('Iteration', 4751, 'Current Value of RSS (Cost Function) based on updated values of beta parameters = ', 0.6931472201516163)\n",
      "Training Interrupted as Maximum number of iterations were crossed.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# m = Number of training examples\n",
    "# n = number of features\n",
    "m, n = X.shape\n",
    "\n",
    "# initialize theta(weights) parameters to zeros\n",
    "betas = np.zeros(1+n)\n",
    "#print(theta)\n",
    "\n",
    "# set learning rate to 0.01 and number of iterations to 500\n",
    "learning_rate = 0.0000000001\n",
    "num_iter = 5000\n",
    "cost = gradientDescentAlgorithm(X_std,y,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Logistic Regression')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a plot with number of iterations on the x-axis and the cost function on y-axis\n",
    "plt.plot(range(1, len(cost) + 1), cost)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
